{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1682bcb-e5bc-4700-a0b7-1ca4301a927d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Example Python Code\n",
    "\n",
    "This jupyter notebook is an example for generating a valid netCDF file for uploading to perform the DLC response analysis.\n",
    "\n",
    "Code similar to this example is intended to be used after tank testing or a dynamic simulation of your WEC device is performed, using the surface elevation time series for your realized sea states downloaded through the DLC Generator tool.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "057ab8f2-1b14-40e1-8074-35cdfc526f7d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports - NOTE: xarray issues a warning for a backend engine that isn't needed for this code\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy.integrate import solve_ivp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c3546-72bf-4b2d-bb1b-df13f35600a5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Structure\n",
    "\n",
    "The data structure used is a netCDF file, where the coordinates are **time** and **case**, and the variables are the response value arrays that are indexed by case and time.\n",
    "\n",
    "## Data structure requirements\n",
    "\n",
    "1. Sample rate (time variable) needs to be consistent across all cases and response variables. \n",
    "2. Data variables (device response arrays) need to exist across all cases. IE Case 1 having 4 response variables and Case 2 having 5 is invalid. Both would need 5 response variables.\n",
    "3. Time array is in seconds (simulation/ tank time), NOT a datetime or string. \n",
    "4. No NaN's/ nulls can be present in response data variables.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efe45ace-b495-4560-b54f-bc8871b6266d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data that would come from tank testing or dynamic simulation\n",
    "\n",
    "Suppose you've calculated contour statistics for a data source and computed 2 sea states from the Hm50 contour line. Having downloaded the surface elevation traces, we can perform a simulation to generate some WEC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a37ae1ed-e008-4b0c-9202-d18c126c90c4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the Hm0, Tp values for the  downloaded cases\n",
    "sea_states = [\n",
    "    {\"Hm0\": 11.92, \"Tp\": 10.20},\n",
    "    {\"Hm0\": 21.33, \"Tp\": 17.70},\n",
    "]\n",
    "# Helper function for file loading\n",
    "def decimal_to_p(f):\n",
    "    return \"{:.2f}\".format(f).replace(\".\", \"p\")\n",
    "\n",
    "# Combine all the wave cases into a single DataFrame\n",
    "elevations = []\n",
    "for sea_state in sea_states:\n",
    "    Hm0 = sea_state[\"Hm0\"]\n",
    "    Tp = sea_state[\"Tp\"]\n",
    "    filename = \"Hm0-{}_Period-{}.csv\".format(decimal_to_p(Hm0), decimal_to_p(Tp))\n",
    "    case = \"DLC 6.2 Hm0: {} Tp: {}\".format(Hm0, Tp)\n",
    "    eta = pd.read_csv(filename, index_col=0, names=[\"time\", case], header=0)\n",
    "\n",
    "    elevations.append(eta)\n",
    "\n",
    "elevation=pd.concat(elevations,axis=1)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform simple simulation\n",
    "Here we perform a very simple simulation for a WEC that experiences a force proportional the surface elevation.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "341d0652-c25f-4300-b990-3340f4eaaefd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = 500 # kg\n",
    "d = 1000 # Ns/m\n",
    "k = 600 # N/m\n",
    "def ode(t, x, case):\n",
    "    eta = elevation[case]\n",
    "    # External force\n",
    "    f_external = 400 * np.interp(t, eta.index.values, eta.values)\n",
    "    pos = x[0]\n",
    "    vel = x[1]\n",
    "\n",
    "    acc = 1/m * (f_external - d * vel - k * pos)\n",
    "\n",
    "    return [vel, acc]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up quantities we want to output\n",
    "These have the same shape as the original surface elevation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pto_displacement = np.zeros(elevation.shape)\n",
    "pto_force = np.zeros(elevation.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the simulation for each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(elevations):\n",
    "    time = data.index.values\n",
    "    sol = solve_ivp(ode, t_span=[time[0], time[-1]], y0 = [0.0, 0.0], t_eval=time, args=(data))\n",
    "\n",
    "    pos = sol.y[0, :]\n",
    "    vel = sol.y[1, :]\n",
    "\n",
    "    force = d*vel + k*pos\n",
    "    \n",
    "    pto_displacement[:, i] = pos\n",
    "    pto_force[:, i] = force"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1 - Create a combined xarray Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.Dataset(\n",
    "    # Create the data variables, indicating they're indexed by case then time.\n",
    "    # Additionally a dictionary of attributes can be provided: 'units' and 'name'\n",
    "    # will be used to display the data in the DLC UI.\n",
    "    data_vars=dict(\n",
    "        pto_displacement=([\"case\", \"time\"], pto_displacement.T, {\"units\":\"m\", \"name\":\"PTO Displacement\"}),\n",
    "        pto_force=([\"case\", \"time\"], pto_force.T, {\"units\":\"N\", \"name\":\"PTO Force\"}),\n",
    "    ),\n",
    "    # The coordinates must be supplied in this form.\n",
    "    coords=dict(\n",
    "        time=time,\n",
    "        case=([\"case\"], elevation.columns)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63379b76-398d-4853-8a7b-c448269a582c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:           (case: 2, time: 216000)\n",
      "Coordinates:\n",
      "  * time              (time) float64 0.0 0.05 0.1 ... 1.08e+04 1.08e+04 1.08e+04\n",
      "  * case              (case) object 'DLC 6.2 Hm0: 11.92 Tp: 10.2' 'DLC 6.2 Hm...\n",
      "Data variables:\n",
      "    pto_displacement  (case, time) float64 0.0 -0.0002085 ... -1.745 -1.757\n",
      "    pto_force         (case, time) float64 0.0 -8.202 ... -1.304e+03 -1.286e+03\n"
     ]
    }
   ],
   "source": [
    "# show data structure\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8c71401-d06c-43bf-a08d-c72abc2bec1e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save data for upload\n",
    "data.to_netcdf(\"response-upload.nc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2 - Create a CSV for each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(elevations):\n",
    "    name = data.columns[0].replace(\" \", \"_\").replace(\":\", \"\")\n",
    "    d = np.array([pto_displacement[:,i], pto_force[:,i]]).T\n",
    "    df = pd.DataFrame(data=d, index=data.index.values, columns=('pto_displacement', \"pto_force\"))\n",
    "    \n",
    "    df.to_csv(name+\".csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/Users/mark/opt/anaconda3/envs/dlc/bin/python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "name": "example.ipynb",
  "vscode": {
   "interpreter": {
    "hash": "a1efd7151ace4617cf718278dd4b64eab211d6fda341c8d7d80b9b77c36f059f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
